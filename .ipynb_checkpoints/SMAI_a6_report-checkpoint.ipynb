{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "## SMAI ASSIGNMENT-6\n",
    "### SUBMITTED BY: AISHWARYA SHIVACHANDRA\n",
    "### ROLL NO. : 2018202005</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Without using any deep learning library, Implement the forward pass of neural network LeNet. Take filter weights as gaussian or random filter and pooling operation as max-pooling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenet Architecture:  INPUT => CONV => RELU => POOL => CONV => RELU => POOL => FC(Conv) => RELU => FC \n",
    "\n",
    "\n",
    "=><u>Algorithm implementation:</u>\n",
    "<br>1.Firstly resize the input image to 32x32x3\n",
    "<br>Then, create first layer filter: 5x5x6\n",
    "<br>Now apply convolution and for output, calculate dimensions using:<br>\n",
    "<br>n_out:\n",
    "<img src = \"https://i.imgur.com/nJevMsX.png\" width=\"300px\" height=\"300px\"></img>\n",
    "\n",
    "\n",
    "<br>2. Convolution Layer: Here, we compute the output by dot product between all filters and image patch.\n",
    "<br>Convolution Result Dimensions: (28, 28, 6)\n",
    "\n",
    "<br>3. Activation Function Layer: This layer will apply element wise activation function to the output of convolution layer. <br>\n",
    "output will have dimensions:(28, 28, 6)\n",
    "\n",
    "<br>4. Pool Layer: Here, we use a max pool with 2 x 2 filters and stride 2, <br> New image dimension after 1st pooling:(14, 14, 6)\n",
    "\n",
    "<br>5.Fully-Connected Layer: This layer is regular neural network layer which takes input from the previous layer and computes the class scores and outputs the 1-D array of size equal to the number of classes.\n",
    "<br><br><br>\n",
    "<u>Results and observations:</u><br>\n",
    "<br>\n",
    "\n",
    "<br><br><b><center>Original Image:</center></b>\n",
    "<img src = \"https://i.imgur.com/C9RMLZI.png\" width=\"300px\" height=\"300px\"></img>\n",
    "<b><br>Resized image:</b><br>Image new Dimensions:  (32, 32, 4)<br>\n",
    "<img src = \"https://i.imgur.com/JL4HTV7.png\" width=\"250px\" height=\"250px\"></img>\n",
    "\n",
    "<b><br>1st layer filter image:</b><br>Filter Dimensions:  (5, 5, 6)<br>\n",
    "<img src = \"https://i.imgur.com/3A3bHYh.png\" width=\"250px\" height=\"250px\"></img>\n",
    "\n",
    "<b><br>1st layer convolution image:</b><br>Convolution Result Dimensions: (28, 28, 6)<br>\n",
    "<img src = \"https://i.imgur.com/ta6W3LA.png\" width=\"250px\" height=\"250px\"></img>\n",
    "\n",
    "<b><br>1st layer relu result image:</b><br>ReLU Result Dimensions: (28, 28, 6)<br>\n",
    "<img src = \"https://i.imgur.com/xgWbMWV.png\" width=\"250px\" height=\"250px\"></img>\n",
    "\n",
    "<b>Final output:</b><br> [ 0.05466102 0.09538095 0.05697193 0.13039827 0.05376791 0.08540897 0.14596092 0.08680363 0.14518655 0.14545985]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Answer the following questions for above architecture:\n",
    "### 1. What are the number of parameters in 1st convolutional layers ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> <u>APPROACH USED:</u><br>Filter size =nxm\n",
    "<br>the input feature maps=l<br>\n",
    "output feature maps = k<br>\n",
    "Then, total number of parameters in convolutional layer= n x m x l x k + k\n",
    "<br><br><u>=> Results & observations:</u>\n",
    "<br> <b>For first convolutional layer:</b><br> filter size= 5x5\n",
    "<br>l=3 i.e. no of channels in rgb image \n",
    "<br>k=6,we need 6 such filters each having one bias entry\n",
    "<br>Then, total number of parameters in convolutional layer= (n x m x l+1) x k = 5x5x3x6 + 6= 456\n",
    "<br> <b>For second convolutional layer:</b><br> filter size= 5x5\n",
    "<br>l=6\n",
    "<br>k=16,we need 16 such filters each having one bias entry\n",
    "<br>Then, total number of parameters in convolutional layer= (n x m x l+1) x k =  5x5x6x16 + 16=2416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What are the number of parameters in pooling operation?\n",
    "=>The pooling layers works as:<br> \"replace a 2x2 neighborhood by its maximum value\".<br>So there is no parameter to learn in a pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Which of the following operations contain most number of parameters?\n",
    "### (a) conv (b) pool (c) Fully connected layer (FC) (d) Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=>Calculating parameters:<br><b>a)For conv: </b>456 + 2416=2872 parameters\n",
    "<br><b>b)For pool: </b>0 parameters\n",
    "<br><b>c)For Fully connected layer (FC): </b>\n",
    "<br>Fully-connected layers: In a fully-connected layer, all input units have a separate weight to each output unit. For n inputs and m outputs, the number of weights is n*m. Additionally, you have a bias for each output node, so you are at (n+1)*m parameters.\n",
    "<br> FC1=(16x5x5+1) x 120=48120\n",
    "<br> FC2=(120+1) x 84=10164\n",
    "<br> FC3=(84+1) x 10= 850<br>\n",
    "Total, 59134 parameters.\n",
    "<br><b>d) Activation Functions: </b>0 parameters\n",
    "<br><br>\n",
    "<u>=> Results & observations:</u><br>\n",
    "Thus, Fully connected layer contains most number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which operation consume most amount of memory?\n",
    "### (a) initial convolution layers (b) fully connected layers at the end\n",
    "=><b>a)initial convolution layers: </b><br>As shown in above question, convolution layers take 2872 parameters.\n",
    "<br><b>b)For Fully connected layer: </b>\n",
    "<br>Fully-connected layers: In a fully-connected layer, all input units have a separate weight to each output unit. For n inputs and m outputs, the number of weights is n*m. Additionally, you have a bias for each output node, so you are at (n+1)*m parameters. so, 48120+10164+850=59134 parameters.<br>So, since computations on these parameters will take as much time. Thus, we can infer that Fully connected layers will consume most amount of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Try different activation functions and describe observations.\n",
    "\n",
    "=>SIGMOID:<br>\n",
    "\n",
    "output - [ 0.05466102  0.09538095  0.05697193  0.13039827  0.05376791  0.08540897\n",
    "  0.14596092  0.08680363  0.14518655  0.14545985]\n",
    "  \n",
    "=> ReLU:<br>\n",
    "\n",
    "output - [ 0.0040791   0.0040791   0.0040791   0.74208166  0.0040791   0.11819261\n",
    "  0.01269768  0.08496555  0.01287573  0.01287037]\n",
    "\n",
    "=>tanH:<br>\n",
    "\n",
    "output - [  8.86531717e-01   6.92530743e-04   2.06223543e-02   3.29971588e-05\n",
    "   6.72524087e-03   2.92757954e-05   3.79493273e-02   1.03535808e-03\n",
    "   1.07095328e-05   4.63704893e-02]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 [Tensorflow framework]. The notebook contain following TODO part:\n",
    "### 1. Barebone Tensorflow (low level APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of neural network we build for Apparel dataset is designed to work on classification problems. But this dataset consists of categorical values, and it is a regression problem. So we need to make the following modifications:-<br>\n",
    "<br>1) Since, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keras Model API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of neural network we build for Apparel dataset is designed to work on classification problems. But this dataset consists of categorical values, and it is a regression problem. So we need to make the following modifications:-<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Keras Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CIFAR-10 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://i.imgur.com/mgBhRiH.png\" width=\"300px\" height=\"550px\" align=\"left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write an explanation of what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of neural network we build for Apparel dataset is designed to work on classification problems. But this dataset consists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
